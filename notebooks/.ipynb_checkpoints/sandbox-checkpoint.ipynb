{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decreased-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from functools import lru_cache\n",
    "import genomicsurveillance as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coastal-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genomicsurveillance.data import get_geodata, get_meta_data\n",
    "from genomicsurveillance.utils import create_spline_basis, create_dates_df\n",
    "from genomicsurveillance.gov_uk import get_specimen\n",
    "from genomicsurveillance.handler import SVIModel\n",
    "from genomicsurveillance.models import Sites\n",
    "from genomicsurveillance.distributions import *\n",
    "import numpy as np\n",
    "import numpyro as npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genomicsurveillance.handler import SVIHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorporate-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-interaction",
   "metadata": {},
   "source": [
    "## Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuous-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = get_meta_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "analyzed-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = uk[uk.ctry19nm == 'England']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-season",
   "metadata": {},
   "source": [
    "## Get cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tribal-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases = get_specimen() \n",
    "cases = pd.read_csv('specimen-20210304.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compatible-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = eng.merge(cases, left_on='lad19cd', right_index=True, how='left').iloc[:, -184:-4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-pearl",
   "metadata": {},
   "source": [
    "## Lineage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "marked-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = (pd.read_csv('latest.txt', index_col=0)\n",
    "            .melt(\"WeekEndDate\", var_name=\"loc\", value_name=\"samples\")\n",
    "            .assign(location=lambda df: df[\"loc\"].apply(lambda x: x.split(\"_\")[0]))\n",
    "            .assign(lineage=lambda df: df[\"loc\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:])))\n",
    "            .drop(\"loc\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "knowing-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_dates = lineages.WeekEndDate.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "purple-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages_types = lineages.lineage.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "biological-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = np.stack([\n",
    "    (lineages[lineages.lineage == lineages_types[i]]\n",
    "     .pivot(values=\"samples\", index=\"location\", columns=\"WeekEndDate\")\n",
    "     .merge(eng, left_index=True, right_on='lad19cd', how='right')\n",
    "     .loc[:, lineage_dates[2:]]\n",
    "     .values\n",
    "    )\n",
    "     for i in range(0, len(lineages_types))], -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "honest-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_date_idx = np.array([create_dates_df(cases.shape[1], '2020-09-01').index(date) for date in lineage_dates[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "democratic-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lineages = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "standard-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages_red = np.concatenate([lineages[..., :max_lineages], lineages[..., max_lineages:].sum(-1, keepdims=True)], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moral-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnot_nan_row(array: np.ndarray) -> np.ndarray:\n",
    "    return np.where(~np.isnan(array.sum(axis=tuple(range(1, array.ndim)))))[0]\n",
    "def is_nan_row(array: np.ndarray) -> np.ndarray:\n",
    "    return np.where(np.isnan(array.sum(axis=tuple(range(1, array.ndim)))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-radical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technical-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class IndependentMultiLineage(SVIModel):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cases,\n",
    "        lineages,\n",
    "        lineage_dates,\n",
    "        population,\n",
    "        basis=None,\n",
    "        tau=6.5,\n",
    "        init_scale=0.1,\n",
    "        fit_a=False,\n",
    "        fit_rho=False,\n",
    "        beta_loc=-10.0,\n",
    "        beta_scale=2.0,\n",
    "        mu_a_scale=0.001,\n",
    "        mu_b_scale=0.01,\n",
    "        a_scale=0.001,\n",
    "        b_scale=0.01,\n",
    "        c_scale=5.0,\n",
    "        rho_loc=np.log(25.0),\n",
    "        rho_scale=1.0,\n",
    "        multinomial_scale=1.0,\n",
    "        time_scale=100.0,\n",
    "        exclude=False,\n",
    "        use_correlation=False,\n",
    "        use_ar=False,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        RelaxedMultiLineage model\n",
    "        \"\"\"\n",
    "        assert (cases.shape[0] == lineages.shape[0]), \"cases and lineages must have the number of location\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.cases = cases\n",
    "        self.lineages = lineages\n",
    "        self.lineage_dates = lineage_dates\n",
    "        self.population = population\n",
    "        \n",
    "        self.tau = tau\n",
    "        self.init_scale = init_scale\n",
    "        self.fit_rho = fit_rho\n",
    "        self.fit_mu_b_mvn = False\n",
    "\n",
    "        self.beta_loc = beta_loc\n",
    "        self.beta_scale = beta_scale\n",
    "\n",
    "        self.mu_b_loc = 0.0\n",
    "        self.mu_b_scale = mu_b_scale\n",
    "\n",
    "        self.b_loc = 0.0\n",
    "        self.b_scale = b_scale\n",
    "        self.c_loc = -10.0\n",
    "        self.c_scale = c_scale\n",
    "\n",
    "        self.rho_loc = rho_loc\n",
    "        self.rho_scale = rho_scale\n",
    "        self.exclude = exclude\n",
    "\n",
    "        self.use_correlation = use_correlation\n",
    "        self.use_ar = use_ar\n",
    "\n",
    "        self.multinomial_scale = multinomial_scale\n",
    "        self.time_scale = time_scale\n",
    "        \n",
    "\n",
    "        \n",
    "        if basis is None:\n",
    "            _, self.B = create_spline_basis(np.arange(cases.shape[1]), num_knots=int(np.ceil(cases.shape[1] / 10)))\n",
    "        else:\n",
    "            self.B = basis\n",
    "            \n",
    "    @property\n",
    "    @lru_cache()\n",
    "    def _nan_idx(self):\n",
    "        exclude = list(set(is_nan_row(self.lineages)) | set(is_nan_row(self.cases)))\n",
    "        return np.array([i for i in range(self.cases.shape[1]) if i not in exclude])\n",
    "    \n",
    "    @property\n",
    "    @lru_cache()\n",
    "    def _missing_lineages(self):\n",
    "        return (self.lineages[..., :-1].sum(1) != 0)[self._nan_idx].astype(int)\n",
    "\n",
    "    def _pad(self, name, array, index, shape, func):\n",
    "        \"\"\"Expands the array to the full size shape\"\"\"\n",
    "        expanded_array = jnp.zeros(shape)\n",
    "        expanded_array = index_update(expanded_array, index, array)\n",
    "        return npy.deterministic(\n",
    "            name, jnp.concatenate([expanded_array, func((shape[0], 1, 1))], -1)\n",
    "        )\n",
    "    \n",
    "    def aggregate(self):\n",
    "        # Regression coefficients (num_location x num_basis)\n",
    "        beta_1 = npy.sample(\n",
    "            self.BETA_1,\n",
    "            dist.MultivariateNormal(\n",
    "                self.beta_loc,\n",
    "                jnp.tile(self.beta_scale, (num_countries, num_basis, 1))\n",
    "                * jnp.eye(num_basis).reshape(1, num_basis, num_basis),\n",
    "            ),\n",
    "        )\n",
    "        N_regions = jnp.array([N[C == i].sum(0) for i in range(num_countries)])\n",
    "        f_regions_lineage = jnp.stack(\n",
    "            [jnp.nansum(f_lin[C == i], 0) for i in range(num_countries)], 0\n",
    "        )\n",
    "        f_regions = f_regions_lineage.sum(-1, keepdims=True)\n",
    "        p_regions = npy.deterministic(\"p_regions\", f_regions_lineage / f_regions)\n",
    "        l_regions = jnp.stack(\n",
    "            [jnp.nansum(lineage_red[C == i], 0) for i in range(num_countries)], 0\n",
    "        )\n",
    "\n",
    "        g_regions = jnp.exp(beta_1 @ B[0].T)\n",
    "        print(\"g_regions\", g_regions.shape)\n",
    "        print(\"f_regions\", f_regions.shape)\n",
    "        mu_regions = g_regions * f_regions.squeeze()\n",
    "\n",
    "        lamb_regions_lineage = npy.deterministic(\n",
    "            \"lamb_regions_1\",\n",
    "            N_regions.reshape(-1, 1, 1)\n",
    "            * g_regions[..., jnp.newaxis]\n",
    "            * f_regions_lineage,\n",
    "        )\n",
    "        lamb_regions = npy.deterministic(\n",
    "            \"lamb_regions\", N_regions.reshape(-1, 1) * mu_regions\n",
    "        )\n",
    "        #         R_regions = npy.deterministic('R_regions', jnp.exp(((beta_1 @ B[1].T)[..., jnp.newaxis] + b_1) * self.tau))\n",
    "        b_regions = jnp.stack(\n",
    "            [jnp.nansum(b_1[C == i], 0) for i in range(num_countries)], 0\n",
    "        )\n",
    "        print(\"b_regions\", b_regions.shape)\n",
    "        R_regions = npy.deterministic(\n",
    "            \"R_regions\",\n",
    "            jnp.exp(((beta_1 @ B[1].T)[..., jnp.newaxis] + b_regions) * self.tau),\n",
    "        )\n",
    "\n",
    "        print(\"lamb_regions_lin\", lamb_regions_lineage.shape)\n",
    "        print(\"lamb_regions\", lamb_regions.shape)\n",
    "        npy.sample(\n",
    "            \"lineage_regions\",\n",
    "            MultinomialProbs(\n",
    "                p_regions[:, X],\n",
    "                total_count=l_regions.sum(-1),\n",
    "                scale=self.multinomial_scale,\n",
    "            ),\n",
    "            obs=l_regions,\n",
    "        )\n",
    "\n",
    "        specimen_regions = jnp.stack(\n",
    "            [jnp.nansum(specimen[C == i], 0) for i in range(num_countries)], 0\n",
    "        )\n",
    "        print(\"spe\", specimen_regions.shape)\n",
    "        npy.sample(\n",
    "            \"specimen_regions\",\n",
    "            NegativeBinomial(lamb_regions, jnp.exp(rho)),  # jnp.clip(, 1e-6, 1e6)\n",
    "            obs=specimen_regions,\n",
    "        )\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"The model.\"\"\"\n",
    "        \n",
    "        num_ltla = self.cases.shape[0]\n",
    "        num_time = self.cases.shape[1]\n",
    "        num_lin = self.lineages.shape[-1] - 1\n",
    "        num_basis = self.B.shape[-1]\n",
    "        num_ltla_lin = self._nan_idx.shape[0]\n",
    "        num_time_lin = self.lineages.shape[1]\n",
    "        \n",
    "        plate_time = npy.plate(\"time\", num_time, dim=-1)\n",
    "        plate_ltla = npy.plate(\"ltla\", num_ltla, dim=-2)\n",
    "        plate_basis = npy.plate(\"basis\", num_basis, dim=-1)\n",
    "\n",
    "        plate_lin = npy.plate(\"lin\", num_lin, dim=-1)\n",
    "        plate_lin_time = npy.plate(\"lin_time\", num_time_lin, dim=-2)\n",
    "        plate_lin_ltla = npy.plate(\"lin_ltla\", num_ltla_lin, dim=-3)\n",
    "\n",
    "        # dispersion parameter for lads\n",
    "        if self.fit_rho:\n",
    "            with plate_ltla:\n",
    "                rho = npy.sample(Sites.RHO, dist.Normal(self.rho_loc, self.rho_scale))\n",
    "        else:\n",
    "            with plate_ltla:\n",
    "                rho = self.rho_loc\n",
    "\n",
    "        if self.use_correlation:\n",
    "            print(\"Correlation\")\n",
    "            Σ0 = jnp.eye(num_basis)\n",
    "            for i in range(1, num_basis):\n",
    "                Σ0 = index_update(\n",
    "                    Σ0, index[i, i - 1], jnp.array(0.5)\n",
    "                )  ## correlate neighbouring basis functions\n",
    "\n",
    "        if self.use_ar:\n",
    "            print(\"AR\")\n",
    "            Π0 = jnp.linalg.inv(Σ0)  ### THIS NEEDS TO GO HERE\n",
    "            for i in range(num_basis - 3, num_basis):\n",
    "                Π0 = index_update(Π0, index[i, i - 2 : i], jnp.array([1, -2]))\n",
    "            Π0 = index_update(\n",
    "                Π0,\n",
    "                index[num_basis - 3, num_basis - 5 : num_basis - 3],\n",
    "                0.5 * jnp.array([1, -2]),\n",
    "            )  ## Make last 3 basis functions autoregressive\n",
    "            Σ0 = jnp.linalg.inv(Π0)\n",
    "\n",
    "        # Regression coefficients (num_location x num_basis)\n",
    "        beta_0 = npy.sample(\n",
    "            Sites.BETA_0,\n",
    "            dist.MultivariateNormal(\n",
    "                self.beta_loc,\n",
    "                jnp.tile(self.beta_scale, (num_ltla, num_basis, 1))\n",
    "                * jnp.eye(num_basis).reshape(1, num_basis, num_basis),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        \n",
    "        if self.use_correlation or self.use_ar:\n",
    "            β_0 = npy.sample(\"β_0\", dist.Uniform(-30, 0, num_ltla))\n",
    "            beta_0 = npy.deterministic(\"beta_0\", beta_0 @ Σ0.T + β_0)\n",
    "\n",
    "        # lineage priors\n",
    "        with plate_lin:\n",
    "            if self.fit_mu_b_mvn:\n",
    "                mu_b = npy.sample(\n",
    "                    Sites.MU_B,\n",
    "                    dist.MultivariateNormal(\n",
    "                        self.mu_b_loc, self.mu_b_scale * jnp.eye(num_lin)\n",
    "                    ),\n",
    "                )\n",
    "            else:\n",
    "                mu_b = npy.sample(\n",
    "                    Sites.MU_B,\n",
    "                    dist.Normal(\n",
    "                        self.time_scale * self.mu_b_loc,\n",
    "                        self.time_scale * self.mu_b_scale,\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        mu_bc = jnp.concatenate(\n",
    "            [\n",
    "                self._missing_lineages * jnp.repeat(mu_b.reshape(1, -1), num_ltla_lin, 0),\n",
    "                jnp.repeat(\n",
    "                    jnp.repeat(self.c_loc, num_lin).reshape(1, -1), num_ltla_lin, 0\n",
    "                ),\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        \n",
    "        sd_bc = jnp.repeat(\n",
    "            jnp.diag(\n",
    "                jnp.concatenate(\n",
    "                    [\n",
    "                        self.time_scale * jnp.repeat(self.b_scale, num_lin),\n",
    "                        jnp.repeat(self.c_scale, num_lin),\n",
    "                    ]\n",
    "                )\n",
    "            ).reshape(1, 2 * num_lin, 2 * num_lin),\n",
    "            num_ltla_lin,\n",
    "            0,\n",
    "        )\n",
    "        bc = npy.sample(\"bc\", dist.MultivariateNormal(mu_bc, sd_bc)).reshape(\n",
    "            num_ltla_lin, 2, num_lin\n",
    "        )\n",
    "        \n",
    "        # pad lineage parameters b, c to match the full size array\n",
    "        b_1 = self._pad(\n",
    "            Sites.B_1,\n",
    "            bc[:, 0].reshape(num_ltla_lin, 1, -1) / self.time_scale,\n",
    "            index[self._nan_idx, :, :],\n",
    "            (num_ltla, 1, num_lin),\n",
    "            jnp.zeros,\n",
    "        )\n",
    "        c_1 = self._pad(\n",
    "            Sites.C_1,\n",
    "            bc[:, 1].reshape(num_ltla_lin, 1, -1),\n",
    "            index[self._nan_idx, :, :],\n",
    "            (num_ltla, 1, num_lin),\n",
    "            jnp.zeros,\n",
    "        )\n",
    "\n",
    "        # Lineage specific regression coefficients (num_ltla x num_basis x num_lin)\n",
    "        f_lin = jnp.exp(b_1 * jnp.arange(num_time).reshape(1, -1, 1) + c_1)\n",
    "        f = f_lin.sum(-1, keepdims=True)\n",
    "\n",
    "        p = npy.deterministic(Sites.P, f_lin / f)\n",
    "        print(\"p\", p.shape)\n",
    "\n",
    "        if self.exclude:\n",
    "            print(\"excluding missing lineages\")\n",
    "            p = index_update(p, exclude, 0.0)\n",
    "\n",
    "        g = jnp.exp(beta_0 @ self.B[0].T)\n",
    "        mu = g * f.squeeze()\n",
    "        lamb_1 = npy.deterministic(\n",
    "            Sites.LAMB_1, self.population.reshape(-1, 1, 1) * g[..., jnp.newaxis] * f_lin\n",
    "        )\n",
    "        lamb = npy.deterministic(Sites.LAMB, self.population.reshape(-1, 1) * mu)\n",
    "        G_r = npy.deterministic(\"G\", beta_0 @ self.B[1].T)\n",
    "        R_1 = npy.deterministic(\n",
    "            Sites.R_1, jnp.exp(((beta_0 @ self.B[1].T)[..., jnp.newaxis] + b_1) * self.tau)\n",
    "        )\n",
    "\n",
    "        sa = npy.deterministic(\"sa\", jnp.exp(mu_b / self.time_scale * self.tau))\n",
    "\n",
    "\n",
    "        npy.sample(\n",
    "            Sites.SPECIMEN,\n",
    "            NegativeBinomial(lamb[self._nan_idx], jnp.exp(rho)),  # jnp.clip(, 1e-6, 1e6)\n",
    "            obs=self.cases[self._nan_idx],\n",
    "        )\n",
    "\n",
    "        # with lineage_context:\n",
    "        npy.sample(\n",
    "            Sites.LINEAGE,\n",
    "            MultinomialProbs(\n",
    "                p[self._nan_idx][:, self.lineage_dates], total_count=self.lineages[self._nan_idx].sum(-1), scale=self.multinomial_scale\n",
    "            ),\n",
    "            obs=self.lineages[self._nan_idx],\n",
    "        )\n",
    "\n",
    "    def guide(self):\n",
    "        num_ltla = self.cases.shape[0]\n",
    "        num_time = self.cases.shape[1]\n",
    "        num_lin = self.lineages.shape[-1] - 1\n",
    "        num_basis = self.B.shape[-1]\n",
    "        num_ltla_lin = self._nan_idx.shape[0]\n",
    "        num_time_lin = self.lineages.shape[1]\n",
    "\n",
    "        if self.fit_rho:\n",
    "            rho_loc = npy.param(\n",
    "                Sites.RHO + Sites.LOC,\n",
    "                self.rho_loc * jnp.ones((num_ltla, 1)),\n",
    "            )\n",
    "            rho_scale = npy.param(\n",
    "                Sites.RHO + Sites.SCALE,\n",
    "                self.init_scale * self.rho_scale * jnp.ones((num_ltla, 1)),\n",
    "                constraint=dist.constraints.positive,\n",
    "            )\n",
    "            rho = npy.sample(Sites.RHO, dist.Normal(rho_loc, rho_scale))\n",
    "\n",
    "        # mean / sd for parameter s\n",
    "        beta_0_loc = npy.param(\n",
    "            Sites.BETA_0 + Sites.LOC, self.beta_loc * jnp.ones((num_ltla, num_basis))\n",
    "        )\n",
    "        beta_0_scale = npy.param(\n",
    "            Sites.BETA_0 + Sites.SCALE,\n",
    "            self.init_scale\n",
    "            * self.beta_scale\n",
    "            * jnp.stack(num_ltla * [jnp.eye(num_basis)]),\n",
    "            constraint=dist.constraints.lower_cholesky,\n",
    "        )\n",
    "\n",
    "        # cov = jnp.matmul(β_σ, jnp.transpose(β_σ, (0, 2, 1)))\n",
    "        beta_0 = npy.sample(\n",
    "            Sites.BETA_0, dist.MultivariateNormal(beta_0_loc, scale_tril=beta_0_scale)\n",
    "        )  # cov\n",
    "\n",
    "        # mean / sd for parameter s\n",
    "#         beta_1_loc = npy.param(\n",
    "#             Sites.BETA_1 + Sites.LOC, self.beta_loc * jnp.ones((num_countries, num_basis))\n",
    "#         )\n",
    "#         beta_1_scale = npy.param(\n",
    "#             Sites.BETA_1 + Sites.SCALE,\n",
    "#             self.init_scale\n",
    "#             * self.beta_scale\n",
    "#             * jnp.stack(num_countries * [jnp.eye(num_basis)]),\n",
    "#             constraint=dist.constraints.lower_cholesky,\n",
    "#         )\n",
    "\n",
    "#         # cov = jnp.matmul(β_σ, jnp.transpose(β_σ, (0, 2, 1)))\n",
    "#         beta_1 = npy.sample(\n",
    "#             Sites.BETA_1, dist.MultivariateNormal(beta_1_loc, scale_tril=beta_1_scale)\n",
    "#         )  # cov\n",
    "\n",
    "        mu_b_loc = npy.param(Sites.MU_B + Sites.LOC, jnp.repeat(self.mu_b_loc, num_lin))\n",
    "\n",
    "        if self.fit_mu_b_mvn:\n",
    "            mu_b_scale = npy.param(\n",
    "                Sites.MU_B + Sites.SCALE,\n",
    "                jnp.diag(self.init_scale * self.mu_b_scale * jnp.ones(num_lin)),\n",
    "                constraint=dist.constraints.lower_cholesky,\n",
    "            )\n",
    "            mu_b = npy.sample(\n",
    "                Sites.MU_B, dist.MultivariateNormal(mu_b_loc, scale_tril=mu_b_scale)\n",
    "            )\n",
    "        else:\n",
    "            mu_b_scale = npy.param(\n",
    "                Sites.MU_B + Sites.SCALE,\n",
    "                self.init_scale * self.mu_b_scale * self.time_scale * jnp.ones(num_lin),\n",
    "                constraint=dist.constraints.positive,\n",
    "            )\n",
    "            mu_b = npy.sample(Sites.MU_B, dist.Normal(mu_b_loc, mu_b_scale))\n",
    "\n",
    "        bc_loc = npy.param(\n",
    "            \"bc_loc\",\n",
    "            jnp.repeat(\n",
    "                jnp.concatenate(\n",
    "                    [self.b_loc * jnp.ones(num_lin), self.c_loc * jnp.ones(num_lin)]\n",
    "                ).reshape(1, -1),\n",
    "                num_ltla_lin,\n",
    "                0,\n",
    "            ),\n",
    "        )\n",
    "        bc_scale = npy.param(\n",
    "            \"bc_scale\",\n",
    "            jnp.repeat(\n",
    "                jnp.diag(\n",
    "                    jnp.concatenate(\n",
    "                        [\n",
    "                            self.init_scale\n",
    "                            * self.b_scale\n",
    "                            * self.time_scale\n",
    "                            * jnp.ones(num_lin),\n",
    "                            self.init_scale * self.c_scale * jnp.ones(num_lin),\n",
    "                        ]\n",
    "                    )\n",
    "                ).reshape(1, 2 * num_lin, 2 * num_lin),\n",
    "                num_ltla_lin,\n",
    "                0,\n",
    "            ),\n",
    "            constraint=dist.constraints.lower_cholesky,\n",
    "        )\n",
    "\n",
    "        npy.sample(\"bc\", dist.MultivariateNormal(bc_loc, scale_tril=bc_scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "isolated-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IndependentMultiLineage(cases, lineages_red, lineage_date_idx, eng.pop18.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "figured-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p (317, 180, 11)\n",
      "p (317, 180, 11)\n",
      "p (317, 180, 11)\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "agricultural-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "unauthorized-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "             nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.posterior.mean('beta_0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-creation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
